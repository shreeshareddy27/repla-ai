<p align="center">
  <img src="images/logo.png" width="140" alt="Repla.ai logo" />
</p>

<h1 align="center">Repla.ai</h1>

<p align="center">
  Privacy-first AI Gmail assistant powered by a local LLM (Ollama + Llama 3.1)
</p>

<p align="center">
  Applied AI Systems Project â€” Chrome Extension Ã— Local LLM Ã— Lightweight API Architecture
</p>

---

## ðŸ§  Overview

Repla.ai is a privacy-first AI email assistant that generates contextual Gmail replies using a locally running Large Language Model (Llama 3.1 via Ollama).

Unlike cloud-based AI assistants, **all inference happens locally**:

Gmail â†’ Chrome Extension â†’ Local Express API â†’ Ollama (Llama 3.1) â†’ Draft injected back into Gmail

This project explores:

- Applied LLM integration in real user workflows  
- Local inference vs cloud trade-offs  
- Lightweight API orchestration  
- Prompt conditioning for controlled generation  
- UX + ML system design  

---

## ðŸŽ¯ Problem Statement

Modern AI email tools rely on cloud APIs, raising:

- Privacy concerns  
- Data compliance issues  
- API cost constraints  
- Latency variability  

Repla.ai investigates whether a **fully local LLM pipeline** can deliver useful productivity gains while maintaining complete data privacy.

---

